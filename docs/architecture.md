# アーキテクチャ

## 構成
- frontend (React + Vite)
  - WebSocketでバックエンドと接続
  - UIで推論領域を作成/編集
  - 受信したBase64 JPEGを表示
  - 領域ごとの推論結果をリスト表示
  - モデル一覧を取得し、推論モデルを選択
  - 領域はローカルストレージで保持

- backend (FastAPI + OpenCV + YOLOv8)
  - `/ws/stream` でWebSocket接続を受け付ける
  - 入力ソースに応じて `cv2.VideoCapture` を生成
  - フレームを推論し、画像と領域ごとの結果を返す
  - `/models` で利用可能な `.pt` を返す
  - 重なりが大きい検出は確信度の高い方のみ残す

## データフロー
1. フロントが `start` メッセージで入力ソース/モデル/領域を送信
2. バックエンドがストリームを開き、推論を実行
3. フロントが `regions` 更新メッセージで領域情報を送信
4. バックエンドが最新領域に合わせて結果を返す

## 推論結果の結合
- 領域内の検出ボックスを左端座標の昇順で並べ、ラベルを連結
- 例: "0","1" → `01`

## 座標管理
- フロント内部はピクセル座標、送信時は百分率へ変換する。
